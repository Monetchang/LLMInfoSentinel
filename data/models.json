{
    "models": [
        {
            "title": "deepseek-ai/DeepSeek-R1-Zero",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Zero",
            "time": "2025-03-27T04:02:04",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 876.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1",
            "time": "2025-03-27T04:01:59",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 11700.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-V3-0324",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-V3-0324",
            "time": "2025-03-27T04:01:53",
            "details": {
                "introduction": "Not found..."
            },
            "model_stats": {
                "likes": 1810.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-V3",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-V3",
            "time": "2025-03-27T04:01:45",
            "details": {
                "introduction": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. \nTo achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. \nFurthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. \nWe pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. \nComprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models.\nDespite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training.\nIn addition, its training process is remarkably stable. \nThroughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks."
            },
            "model_stats": {
                "likes": 3740.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-V3-Base",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-V3-Base",
            "time": "2025-03-27T04:00:09",
            "details": {
                "introduction": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. \nTo achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. \nFurthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. \nWe pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. \nComprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models.\nDespite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training.\nIn addition, its training process is remarkably stable. \nThroughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks."
            },
            "model_stats": {
                "likes": 1610.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "time": "2025-02-24T03:32:35",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 1090.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            "time": "2025-02-24T03:32:20",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 573.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
            "time": "2025-02-24T03:32:07",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 670.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "time": "2025-02-24T03:31:45",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 479.0,
                "followers": 51000.0
            }
        },
        {
            "title": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            "time": "2025-02-24T03:31:29",
            "details": {
                "introduction": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. \nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrated remarkable performance on reasoning.\nWith RL, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting reasoning behaviors.\nHowever, DeepSeek-R1-Zero encounters challenges such as endless repetition, poor readability, and language mixing. To address these issues and further enhance reasoning performance,\nwe introduce DeepSeek-R1, which incorporates cold-start data before RL.\nDeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. \nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models distilled from DeepSeek-R1 based on Llama and Qwen. DeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\nNOTE: Before running DeepSeek-R1 series models locally, we kindly recommend reviewing theUsage Recommendationsection."
            },
            "model_stats": {
                "likes": 1290.0,
                "followers": 51000.0
            }
        }
    ]
}